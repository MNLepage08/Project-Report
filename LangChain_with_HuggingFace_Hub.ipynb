{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://youtu.be/dD_xNmePdd0"
      ],
      "metadata": {
        "id": "Z8Oi3egkY-pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt7cEUFx-IDv",
        "outputId": "1144fc49-ff6e-454e-a694-93d7d14195ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MROjfLXaGfSJ",
        "outputId": "fcc4e8e2-4145-4c8d-f103-2b71f7ed085a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Installing collected packages: huggingface_hub\n",
            "Successfully installed huggingface_hub-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install python-dotenv\n",
        "# Use that for VSCode\n",
        "# https://pypi.org/project/python-dotenv/"
      ],
      "metadata": {
        "id": "bSRYaEv0_L76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aWfhyOK9XjR"
      },
      "outputs": [],
      "source": [
        "from langchain import HuggingFaceHub, LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "#from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu629YEe_brC",
        "outputId": "32521a21-a4c1-4add-8e08-8ada547673a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'hf_xxx' # put your API Token"
      ],
      "metadata": {
        "id": "77muf_B1I8LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.promptingguide.ai/fr"
      ],
      "metadata": {
        "id": "c6Qae3dnMhpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## t5-base-finetuned-wikiSQL"
      ],
      "metadata": {
        "id": "TSRO9JPGG680"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/mrm8488/t5-base-finetuned-wikiSQL\n",
        "\n",
        "hub_llm = HuggingFaceHub(repo_id='mrm8488/t5-base-finetuned-wikiSQL')\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables = [\"question\"],\n",
        "    template = \"Translate English to SQL: {question}\"\n",
        ")\n",
        "\n",
        "hub_chain = LLMChain(prompt = prompt, llm=hub_llm, verbose=True)\n",
        "print(hub_chain.run(\"what is the average age of the respondents using a mobile device?\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h4dVZ8FA3LE",
        "outputId": "18f7d9c8-0a46-4ec9-8abe-acc7b32b3c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mTranslate English to SQL: what is the average age of the respondents using a mobile device?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "SELECT AVG Age (years) FROM table WHERE Device = mobile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT2"
      ],
      "metadata": {
        "id": "zy99DwFBHGwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/gpt2\n",
        "\n",
        "hub_llm = HuggingFaceHub(\n",
        "    repo_id='gpt2',\n",
        "    model_kwargs={'temperature':0.8, 'max_length':100}\n",
        "    )\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables = [\"profession\"],\n",
        "    template = \"You had one job! 🙂 You're the {profession} and you didn't have to be sarcastic\"\n",
        ")\n",
        "\n",
        "hub_chain = LLMChain(prompt = prompt, llm=hub_llm, verbose=True)\n",
        "print(hub_chain.run(\"customer service agent\"))\n",
        "print(hub_chain.run(\"politician\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehSGiVQFVa9H",
        "outputId": "f53c30dc-aecf-4fb7-cb6a-8af61b6b1b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou had one job! 🙂 You're the customer service agent and you didn't have to be sarcastic\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            ". You were just a good guy.\n",
            "\n",
            "I'm not sure if you've ever been to a restaurant where you were treated like a customer. I've never been to a restaurant where you were treated like a customer. I've never been to a restaurant where you were treated like a customer.\n",
            "\n",
            "I'm not sure if you've ever been to a restaurant where you were treated like a\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou had one job! 🙂 You're the politician and you didn't have to be sarcastic\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            ". You were just a good guy. You were a good person. You were a good person. You were a good person. You were a good person. You were a good person. You were a good person. You were a good person. You were a good person. You were a good person. You were a good person. You were a good person. You were a good person. You were\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://youtu.be/Kn7SX2Mx_Jk"
      ],
      "metadata": {
        "id": "aRUSfalHJ-4_"
      }
    }
  ]
}
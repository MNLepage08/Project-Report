{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://youtu.be/dD_xNmePdd0"
      ],
      "metadata": {
        "id": "Z8Oi3egkY-pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt7cEUFx-IDv",
        "outputId": "dd38428a-b3f2-4b95-ce29-be5156bcf713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m892.2/892.2 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MROjfLXaGfSJ",
        "outputId": "b2a52c3e-8eae-4e0e-b68a-4ed32ee18e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Installing collected packages: huggingface_hub\n",
            "Successfully installed huggingface_hub-0.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install python-dotenv\n",
        "# Use that for VSCode\n",
        "# https://pypi.org/project/python-dotenv/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSRYaEv0_L76",
        "outputId": "777fdfd3-d9ff-44d4-b1ac-20efd6ef39ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aWfhyOK9XjR"
      },
      "outputs": [],
      "source": [
        "from langchain import HuggingFaceHub, LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "#from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu629YEe_brC",
        "outputId": "32521a21-a4c1-4add-8e08-8ada547673a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'hf_xxxxxxx' # put your API token"
      ],
      "metadata": {
        "id": "77muf_B1I8LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.promptingguide.ai/fr"
      ],
      "metadata": {
        "id": "c6Qae3dnMhpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/mrm8488/t5-base-finetuned-wikiSQL\n",
        "\n",
        "hub_llm = HuggingFaceHub(repo_id='mrm8488/t5-base-finetuned-wikiSQL')\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables = [\"question\"],\n",
        "    template = \"Translate English to SQL: {question}\"\n",
        ")\n",
        "\n",
        "hub_chain = LLMChain(prompt = prompt, llm=hub_llm, verbose=True)\n",
        "print(hub_chain.run(\"what is the average age of the respondents using a mobile device?\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h4dVZ8FA3LE",
        "outputId": "5d4d7437-5897-4623-eee3-b27784c9808a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mTranslate English to SQL: what is the average age of the respondents using a mobile device?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "SELECT AVG Age (years) FROM table WHERE Device = mobile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/gpt2\n",
        "\n",
        "hub_llm = HuggingFaceHub(\n",
        "    repo_id='gpt2',\n",
        "    model_kwargs={'temperature':0.8, 'max_length':100}\n",
        "    )\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables = [\"profession\"],\n",
        "    template = \"You had one job! 🙂 You're the {profession} and you didn't have to be sarcastic\"\n",
        ")\n",
        "\n",
        "hub_chain = LLMChain(prompt = prompt, llm=hub_llm, verbose=True)\n",
        "print(hub_chain.run(\"customer service agent\"))\n",
        "print(hub_chain.run(\"politician\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehSGiVQFVa9H",
        "outputId": "ef1c4e8f-820f-4406-beb0-47d748360f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou had one job! 🙂 You're the customer service agent and you didn't have to be sarcastic\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            ".\n",
            "\n",
            "The problem with being a customer service agent is that you're not the biggest star of the bunch. No, you're the customer service agent who will take your complaints about your company seriously and let you know how great each one of your employees are.\n",
            "\n",
            "This is your job, and you'll be responsible for responding quickly and efficiently to any complaints you see. And because your company\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou had one job! 🙂 You're the politician and you didn't have to be sarcastic\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            ", you didn't have to be bitter or angry!\n",
            "\n",
            "\"A lot of the work you did was to make sure you could work on a different side as quickly as possible. You were probably in a position where you had to deal with some of the criticism that you get. The criticism is not just about you, and it's not about your life.\"\n",
            "\n",
            "The best way to address criticism is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://youtu.be/Kn7SX2Mx_Jk"
      ],
      "metadata": {
        "id": "aRUSfalHJ-4_"
      }
    }
  ]
}